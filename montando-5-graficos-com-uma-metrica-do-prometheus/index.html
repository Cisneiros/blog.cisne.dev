<!DOCTYPE html><html lang="pt-BR" class=" "><head><meta name="generator" content="React Static"/><title data-react-helmet="true">Montando 5 gr√°ficos com uma m√©trica do Prometheus ¬∑ Cisne.dev blog</title><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5, shrink-to-fit=no"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:creator" content="Cisneiros"/><meta data-react-helmet="true" property="og:title" content="Montando 5 gr√°ficos com uma m√©trica do Prometheus ¬∑ Cisne.dev blog"/><meta data-react-helmet="true" property="og:image" content="https://blog.cisne.dev/montando-5-graficos-com-uma-metrica-do-prometheus/social-image.png"/><meta data-react-helmet="true" name="twitter:title" content="Montando 5 gr√°ficos com uma m√©trica do Prometheus ¬∑ Cisne.dev blog"/><meta data-react-helmet="true" name="twitter:image" content="https://blog.cisne.dev/montando-5-graficos-com-uma-metrica-do-prometheus/social-image.png"/><link rel="preload" as="script" href="/templates/vendors~__react_static_root__/src/containers/post~__react_static_root__/src/containers/postList.207edc50.js"/><link rel="preload" as="script" href="/templates/__react_static_root__/src/containers/post~__react_static_root__/src/containers/postList.a04ea84b.js"/><link rel="preload" as="script" href="/templates/__react_static_root__/src/containers/post.d8dd52db.js"/><link rel="preload" as="script" href="/templates/vendors~main.272ae1d1.js"/><link rel="preload" as="script" href="/main.f19d4c14.js"/><link data-react-helmet="true" rel="stylesheet" href="//unpkg.com/dracula-prism/dist/css/dracula-prism.min.css"/><style data-styled="" data-styled-version="5.1.1">.CfxHf{max-width:960px;margin:0 auto;position:relative;}/*!sc*/
data-styled.g1[id="ui__Fit-prwz6b-0"]{content:"CfxHf,"}/*!sc*/
.iuDFSN{padding:1rem;color:var(--color-mid);text-align:center;font-size:1.5rem;}/*!sc*/
.iuDFSN a,.iuDFSN a:hover{-webkit-text-decoration:none;text-decoration:none;color:inherit;}/*!sc*/
data-styled.g2[id="Navigation__Container-sc-1yk0pqp-0"]{content:"iuDFSN,"}/*!sc*/
.izuwCZ{max-width:960px;margin:0 auto;position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g3[id="Navigation__NavFit-sc-1yk0pqp-1"]{content:"izuwCZ,"}/*!sc*/
.TctaC{width:2.5rem;height:1.2em;overflow:hidden;--default-rotation:-180deg;}/*!sc*/
@media (prefers-color-scheme:dark){.TctaC{--default-rotation:0;}}/*!sc*/
data-styled.g4[id="Navigation__BrightnessContainer-sc-1yk0pqp-2"]{content:"TctaC,"}/*!sc*/
.sLeDt{-webkit-transform:rotate(var(--default-rotation));-ms-transform:rotate(var(--default-rotation));transform:rotate(var(--default-rotation));-webkit-transition:-webkit-transform 0.3s ease-out;-webkit-transition:transform 0.3s ease-out;transition:transform 0.3s ease-out;}/*!sc*/
html.light .sLeDt{-webkit-transform:rotate(-180deg);-ms-transform:rotate(-180deg);transform:rotate(-180deg);}/*!sc*/
html.dark .sLeDt{-webkit-transform:rotate(0);-ms-transform:rotate(0);transform:rotate(0);}/*!sc*/
data-styled.g5[id="Navigation__BrightnessSpinner-sc-1yk0pqp-3"]{content:"sLeDt,"}/*!sc*/
.frsARl{background:none;border:none;cursor:pointer;}/*!sc*/
.frsARl:last-child{-webkit-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg);}/*!sc*/
data-styled.g7[id="Navigation__BrightnessIcon-sc-1yk0pqp-5"]{content:"frsARl,"}/*!sc*/
.gdHjSq{margin-top:3rem;padding:1rem;background:var(--color-foreground);color:var(--color-background);}/*!sc*/
.gdHjSq a{color:var(--text-inverse-color-1);}/*!sc*/
.gdHjSq a:hover{color:var(--text-inverse-color-3);}/*!sc*/
data-styled.g8[id="Footer__Container-b3q04c-0"]{content:"gdHjSq,"}/*!sc*/
.layJcq{max-width:960px;margin:0 auto;position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g9[id="Footer__FooterFit-b3q04c-1"]{content:"layJcq,"}/*!sc*/
*{box-sizing:border-box;margin:0;padding:0;border:0;font-size:inherit;font-weight:inherit;font-style:inherit;}/*!sc*/
:root{--color-1:#12c2e9;--color-2:#c471ed;--color-3:#f64f59;--color-1-darker:#0A7B94;--color-2-darker:#AE3CE7;--color-3-darker:#E90C1B;--color-light:#fefefe;--color-dark:#030303;--color-mid-dark:#747481;--color-mid-light:#818181;--font-weight-light:300;--font-weight-regular:400;--font-weight-heavy:500;--font-family-light:"HelveticaNeue-Light","Helvetica Neue Light",'Helvetica Neue',sans-serif;--font-family:'Helvetica Neue',sans-serif;}/*!sc*/
strong,h1,h2,h3,h4,h5,h6{font-family:var(--font-family);}/*!sc*/
html{font-family:var(--font-family-light);font-size:20px;line-height:1;color:var(--color-foreground);background-color:var(--color-background);text-rendering:optimizeLegibility;}/*!sc*/
@media (max-width:600px){html{font-size:16px;}}/*!sc*/
html,html.light{--color-background:var(--color-light);--color-foreground:var(--color-dark);--color-mid:var(--color-mid-dark);--text-color-1:var(--color-1-darker);--text-color-2:var(--color-2-darker);--text-color-3:var(--color-3-darker);--text-inverse-color-1:var(--color-1);--text-inverse-color-2:var(--color-2);--text-inverse-color-3:var(--color-3);}/*!sc*/
html.dark{--color-background:var(--color-dark);--color-foreground:var(--color-light);--color-mid:var(--color-mid-light);--text-color-1:var(--color-1);--text-color-2:var(--color-2);--text-color-3:var(--color-3);--text-inverse-color-1:var(--color-1-darker);--text-inverse-color-2:var(--color-2-darker);--text-inverse-color-3:var(--color-3-darker);}/*!sc*/
@media (prefers-color-scheme:dark){html{--color-background:var(--color-dark);--color-foreground:var(--color-light);--color-mid:var(--color-mid-light);}}/*!sc*/
body{font-size:1em;font-weight:var(--font-weight-light);}/*!sc*/
strong{font-weight:var(--font-weight-heavy);}/*!sc*/
em{font-style:italic;}/*!sc*/
main{padding:1rem;}/*!sc*/
hr{width:30%;margin:4rem auto;border:none;border-bottom:dotted 1px var(--color-1);}/*!sc*/
.pagination{text-align:center;}/*!sc*/
.pagination a{color:var(--text-color-1);}/*!sc*/
.pagination a:hover{color:var(--text-color-3);}/*!sc*/
a{color:var(--text-color-1);-webkit-text-decoration-color:#c471ed80;text-decoration-color:#c471ed80;-webkit-text-decoration-style:wavy;text-decoration-style:wavy;}/*!sc*/
a:hover{color:var(--text-color-3);-webkit-text-decoration-color:#12c2e980;text-decoration-color:#12c2e980;}/*!sc*/
.phone-mockup{max-width:15rem;margin:0 auto 1rem;position:relative;}/*!sc*/
.phone-mockup::before{content:'';width:100%;height:100%;position:absolute;pointer-events:none;background:url(/iphone-11-pro.png) no-repeat;background-size:contain;}/*!sc*/
.phone-mockup video,.phone-mockup img{width:100%;padding:9.3%;}/*!sc*/
data-styled.g14[id="sc-global-hFBrmQ1"]{content:"sc-global-hFBrmQ1,"}/*!sc*/
.tuaWG{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
@media (max-width:600px){.tuaWG{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}/*!sc*/
data-styled.g23[id="Poststyles__AfterPost-sc-12qb97v-0"]{content:"tuaWG,"}/*!sc*/
.gkeqUt{-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/
@media (max-width:600px){.gkeqUt{text-align:center;margin-bottom:1rem;}}/*!sc*/
data-styled.g24[id="Poststyles__AfterPostChild-sc-12qb97v-1"]{content:"gkeqUt,"}/*!sc*/
.fAvgXR{-webkit-flex:1;-ms-flex:1;flex:1;text-align:right;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}/*!sc*/
@media (max-width:600px){.fAvgXR{text-align:center;margin-bottom:1rem;}}/*!sc*/
data-styled.g25[id="Poststyles__Tags-sc-12qb97v-2"]{content:"fAvgXR,"}/*!sc*/
.kSZCZX::before{content:' #';color:var(--color-mid);}/*!sc*/
data-styled.g26[id="Poststyles__Tag-sc-12qb97v-3"]{content:"kSZCZX,"}/*!sc*/
.kyWzPB{-webkit-hyphens:auto;-moz-hyphens:auto;-ms-hyphens:auto;-webkit-hyphens:auto;-moz-hyphens:auto;-ms-hyphens:auto;hyphens:auto;}/*!sc*/
data-styled.g27[id="Poststyles__Container-sc-12qb97v-4"]{content:"kyWzPB,"}/*!sc*/
.hhBwVH{font-size:5rem;font-weight:var(--font-weight-regular);line-height:0.8;background:linear-gradient(var(--color-1),var(--color-2),var(--color-3));-webkit-text-fill-color:transparent;background-clip:text;-webkit-background-clip:text;padding-bottom:1rem;margin:1rem 0;}/*!sc*/
html.rainbow .hhBwVH{background-image:linear-gradient(124deg,#ff2400,#e81d1d,#e8b71d,#e3e81d,#1de840,#1ddde8,#2b1de8,#dd00f3,#dd00f3);-webkit-animation:hTUzwZ 9s ease infinite;animation:hTUzwZ 9s ease infinite;background-size:450% 450%;}/*!sc*/
@media (max-width:600px){.hhBwVH{font-size:3.5rem;}}/*!sc*/
.hhBwVH a{-webkit-text-decoration:none;text-decoration:none;}/*!sc*/
data-styled.g28[id="Poststyles__Title-sc-12qb97v-5"]{content:"hhBwVH,"}/*!sc*/
.fonWHZ{color:var(--color-mid);text-align:center;margin-bottom:2rem;}/*!sc*/
data-styled.g29[id="Poststyles__Meta-sc-12qb97v-6"]{content:"fonWHZ,"}/*!sc*/
.jhgzPU{line-height:1.6;}/*!sc*/
.jhgzPU h2{font-size:2.5rem;}/*!sc*/
.jhgzPU h3{font-size:2rem;}/*!sc*/
.jhgzPU h4{font-size:1.5rem;}/*!sc*/
.jhgzPU h2,.jhgzPU h3,.jhgzPU h4,.jhgzPU h5,.jhgzPU h6{-webkit-hyphens:auto;-moz-hyphens:auto;-ms-hyphens:auto;hyphens:auto;font-weight:var(--font-weight-regular);line-height:0.8;padding-bottom:1rem;margin-top:2rem;}/*!sc*/
.jhgzPU img{max-width:100%;}/*!sc*/
.jhgzPU pre.refractor{margin-top:0;margin-left:0;padding-left:1rem;border-left:solid 0.25rem var(--color-1);border-radius:0;font-size:0.8rem;overflow-wrap:normal;overflow-x:auto;background-color:var(--color-dark);color:var(--color-light);padding-top:0.5rem;padding-bottom:0.5rem;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}/*!sc*/
.jhgzPU pre.refractor::-webkit-scrollbar{width:0.25rem;height:0.25rem;}/*!sc*/
.jhgzPU pre.refractor code,.jhgzPU code{font-family:'Fira Code','Menlo',monospace;}/*!sc*/
.jhgzPU p code{color:var(--text-color-3);}/*!sc*/
.jhgzPU p code,.jhgzPU h1 code,.jhgzPU h2 code,.jhgzPU h3 code,.jhgzPU h4 code,.jhgzPU h5 code,.jhgzPU h6 code{font-size:0.9em;}/*!sc*/
.jhgzPU p,.jhgzPU pre,.jhgzPU ul,.jhgzPU ol,.jhgzPU table,.jhgzPU blockquote,.jhgzPU .live-code-container{margin-bottom:1rem;}/*!sc*/
.jhgzPU twitter-widget{margin-bottom:1rem !important;}/*!sc*/
.jhgzPU p:last-child,.jhgzPU pre:last-child,.jhgzPU ul:last-child,.jhgzPU ol:last-child,.jhgzPU table:last-child,.jhgzPU blockquote:last-child,.jhgzPU .live-code-container:last-child{margin-bottom:0;}/*!sc*/
.jhgzPU ul,.jhgzPU ol{list-style:none;margin-left:1rem;counter-reset:li;}/*!sc*/
.jhgzPU li{counter-increment:li;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/
.jhgzPU ul li::before{content:'‚Ä¢';margin-right:0.5rem;color:var(--color-2);}/*!sc*/
.jhgzPU ol li::before{content:"."counter(li);margin-right:0.5rem;color:var(--color-2);font-weight:var(--font-weight-regular);width:1em;display:inline-block;margin-left:-0.5em;margin-right:0.5em;text-align:right;direction:rtl;}/*!sc*/
.jhgzPU table{margin-left:auto;margin-right:auto;border-spacing:0;font-size:0.9em;}/*!sc*/
.jhgzPU td,.jhgzPU th{border-bottom:solid 1px var(--color-2);padding:0.5rem;}/*!sc*/
.jhgzPU th{font-weight:var(--font-weight-heavy);}/*!sc*/
.jhgzPU tr:hover{background:var(--color-2);}/*!sc*/
.jhgzPU tr:last-of-type td{border-bottom:0;}/*!sc*/
.jhgzPU blockquote{padding-left:1rem;border-left:solid 0.25rem var(--color-3);color:var(--color-mid);}/*!sc*/
data-styled.g30[id="Poststyles__Content-sc-12qb97v-7"]{content:"jhgzPU,"}/*!sc*/
.jjKdZc{position:fixed;top:0;left:0;right:0;height:0.25rem;background-color:var(--color-1);-webkit-transition:opacity 0.25s ease-out;transition:opacity 0.25s ease-out;z-index:2;}/*!sc*/
data-styled.g31[id="post__ScrollTrackerContainer-gh0jqu-0"]{content:"jjKdZc,"}/*!sc*/
@-webkit-keyframes hTUzwZ{0%{background-position:0% 82%;}50%{background-position:100% 19%;}100%{background-position:0% 82%;}}/*!sc*/
@keyframes hTUzwZ{0%{background-position:0% 82%;}50%{background-position:100% 19%;}100%{background-position:0% 82%;}}/*!sc*/
data-styled.g32[id="sc-keyframes-hTUzwZ"]{content:"hTUzwZ,"}/*!sc*/
</style><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="/feed.xml"/></head><body><div id="root"><nav class="Navigation__Container-sc-1yk0pqp-0 iuDFSN"><div class="ui__Fit-prwz6b-0 Navigation__NavFit-sc-1yk0pqp-1 izuwCZ"><p class="logo"><a href="/">Cisne.dev blog</a></p><div class="Navigation__BrightnessContainer-sc-1yk0pqp-2 TctaC"><div class="Navigation__BrightnessSpinner-sc-1yk0pqp-3 sLeDt"><button title="Mudar para modo diurno" aria-label="Mudar para modo diurno" class="Navigation__ClearButton-sc-1yk0pqp-4 Navigation__BrightnessIcon-sc-1yk0pqp-5 frsARl">üåô</button><button title="Mudar para modo noturno" aria-label="Mudar para modo noturno" class="Navigation__ClearButton-sc-1yk0pqp-4 Navigation__BrightnessIcon-sc-1yk0pqp-5 frsARl">‚òÄÔ∏è</button></div></div></div></nav><main><div class="ui__Fit-prwz6b-0 CfxHf"><div><div style="width:0%;opacity:0" class="post__ScrollTrackerContainer-gh0jqu-0 jjKdZc"></div><article class="Poststyles__Container-sc-12qb97v-4 kyWzPB"><h1 class="Poststyles__Title-sc-12qb97v-5 hhBwVH"><a href="/montando-5-graficos-com-uma-metrica-do-prometheus/">Montando 5 gr√°ficos com uma m√©trica do Prometheus</a></h1><p class="Poststyles__Meta-sc-12qb97v-6 fonWHZ">Publicado em <!-- -->20 ago 2020<!-- -->. Uns <!-- -->10<!-- --> minutos de leitura.</p><div class="Poststyles__Content-sc-12qb97v-7 jhgzPU content"><p>A linguagem de consultas do Prometheus, a <strong>PromQL</strong>, permite fazer transforma√ß√µes e agrega√ß√µes das m√©tricas para extrair dados que n√£o haviam sido reportados diretamente pela aplica√ß√£o mas podem ser deduzidos. Nesse post, trago 5 consultas diferentes que podemos fazer para monitorar nossas aplica√ß√µes usando apenas <em>(tecnicamente)</em> uma m√©trica! Vamos us√°-las para montar gr√°ficos no Grafana.</p><span><!-- summary-break --></span><p>Eu digo <em>tecnicamente</em> pois vamos usar uma m√©trica do tipo <strong>histograma</strong>, que √© um <a href="/tipos-complexos-de-metricas-no-prometheus/">tipo complexo de m√©trica do Prometheus</a>. Por baixo, um histograma √© implementado usando v√°rias s√©ries temporais distintas, mas a biblioteca de cliente do Prometheus abstrai isso e a aplica√ß√£o s√≥ precisa registrar cada evento em uma √∫nica m√©trica.</p><p>A m√©trica que vamos usar vai registrar a distribui√ß√£o da lat√™ncia das requisi√ß√µes HTTP que a aplica√ß√£o recebe, em segundos. Vamos cham√°-la de <code>http_request_duration_seconds</code>. Para conseguirmos fazer algumas agrega√ß√µes que queremos, vamos adicionar duas dimens√µes a essta m√©trica: <code>path</code> que √© o caminho (ou endpoint) da requisi√ß√£o e <code>status_class</code> que √© que tipo retorno foi dado a essa requisi√ß√£o, como <code>2XX</code>, <code>4XX</code>, <code>5XX</code>, e por a√≠ vai.</p><p>A cria√ß√£o e registro dos eventos dessa m√©trica depende da linguagem e framework que voc√™ esteja usando. Alguns frameworks possuem integra√ß√£o com a biblioteca de cliente do Prometheus para a linguagem e podem j√° fornecer uma m√©trica como essa. Do contr√°rio, voc√™ precisa observar as requisi√ß√µes que chegam e reportar uma m√©trica de histograma passando como valor o n√∫mero de segundos que ela levou para terminar e, como dimens√µes, pelo menos as duas acima.</p><p>Sobre o <code>path</code>, √© importante lembrar que dimens√µes (labels) no Prometheus n√£o podem ter valores ilimitados, pois isso gera uma carga consider√°vel nele. Uma regra de ouro √©: se voc√™ n√£o consegue listar todas as possibilidades de valores pra uma dimens√£o, ela n√£o deveria existir. Para o <code>path</code>, isso quer dizer que temos que tomar cuidado com <strong>interpola√ß√µes</strong>. Por exemplo, se a aplica√ß√£o tem uma rota <code>/api/users/812376/profile</code>, em que <code>812376</code> representa um ID de usu√°rio, devemos reportar o caminho sem interpola√ß√µes, como <code>/api/users/:id/profile</code>.</p><p>Sobre o <code>status_class</code>, ele √© uma abstra√ß√£o em cima do c√≥digo de status da resposta da nossa aplica√ß√£o. Por exemplo, se a aplica√ß√£o retornar 200 ou 201, o <code>status_class</code> seria <code>2XX</code>. Se retornar 500 ou 503, seria <code>5XX</code>. Isso vai facilitar, por exemplo, filtrarmos todas as requisi√ß√µes em que o servidor deu um erro (<code>5XX</code>) sem ter que listar todos os poss√≠veis c√≥digos de erro HTTP.</p><p>Duas observa√ß√µes antes de come√ßar: algumas dessas m√©tricas, medidas do ponto de vista da aplica√ß√£o, ser√£o naturalmente enviesadas pois considerar√£o apenas requisi√ß√µes que <strong>chegaram a aplica√ß√£o e foram respondidas</strong> (mesmo que com um erro 500). Por√©m, se a aplica√ß√£o estiver mal das pernas, ela pode come√ßar a derrubar conex√µes, ficar indispon√≠vel para reportar m√©tricas, ou ainda um balanceador de carga que sirva a aplica√ß√£o comece a enfileirar requisi√ß√µes e eventualmente desistr delas. Se voc√™ conseguir m√©tricas assim do load balancer, pode ter uma figura mais ver√≠dica nos momento de maior aperto.</p><p>Similarmente, se voc√™ conseguir <strong>coletar m√©tricas no cliente</strong> (navegador, aplicativo, etc), voc√™ consegue considerar falhas em requisi√ß√µes por raz√µes como problemas de DNS, que nem chegariam no seu load balancer. √â tamb√©m poss√≠vel ver lat√™ncia real incluindo o tempo gasto pela conex√£o de rede do usu√°rio, o que √© interessante de analisar pois, mesmo que voc√™ n√£o consiga influenciar muito a velocidade de conex√£o dessa pessoa usando 3G com um pontinho de sinal, entender esse comportamento pode ajudar a otimizar seu conte√∫do para as condi√ß√µes mais t√≠picas do seu usu√°rio.</p><h2>Percentis de lat√™ncia</h2><p>Come√ßando por uma das aplica√ß√µes mais comuns para histogramas no Prometheus: estimar percentis. Para isso, usamos a fun√ß√£o <code>histogram_quantile</code> que espera um n√∫mero de 0 a 1 (por exemplo, 0.5 √© o percentil 50, ou mediana).</p><p>Para esta m√©trica, queremos ver os percentis de lat√™ncia para a aplica√ß√£o toda, independentemente do endpoint ou c√≥digo de retorno. Ent√£o vamos agrupar nossa s√©rie temporal usando <code>sum</code>. Sempre que agregamos s√©ries que v√£o ser usadas para a fun√ß√£o <code>histogram_quantile</code>, precisamos manter a label <code>le</code> (mais sobre isso no <a href="/tipos-complexos-de-metricas-no-prometheus/">post sobre tipos complexos de m√©tricas</a>).</p><pre class="refractor language-js"><code class="language-js"><span class="token function">histogram_quantile</span><span class="token punctuation">(</span><span class="token number">0.99</span><span class="token punctuation">,</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_bucket<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token function">by</span> <span class="token punctuation">(</span>le<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class="refractor language-js"><code class="language-js"><span class="token function">histogram_quantile</span><span class="token punctuation">(</span><span class="token number">0.95</span><span class="token punctuation">,</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_bucket<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token function">by</span> <span class="token punctuation">(</span>le<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class="refractor language-js"><code class="language-js"><span class="token function">histogram_quantile</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_bucket<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token function">by</span> <span class="token punctuation">(</span>le<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><img src="/media/uma-metrica-grafico-1.png" alt="Gr√°fico de percentis de lat√™ncia ao longo do tempo, com tr√™s linhas, cada uma representando um percentil (99, 90 e 50)"/></p><p>Cada consulta acima vai retornar uma s√©rie que representa o percentil de lat√™ncia (99, 90 e 50, respectivamente). Como para o c√°lculo precisamos usar a fun√ß√£o <code>rate</code>, precisamos de uma janela para o c√°lculo da m√©trica. Em todos os exemplos deste post vou usar 5 minutos. Esse valor tem que ser, no m√≠nimo, maior que o dobro do intervalo entre coletas de m√©trica do Prometheus  (<code>scrape_interval</code> na configura√ß√£o), pois voc√™ precisa de dois pontos de dados para calcular a varia√ß√£o.</p><h2>Lat√™ncia m√©dia</h2><p>M√©tricas de histograma incluem, al√©m das s√©ries temporais dos buckets, duas s√©ries a mais que cont√©m a soma de todos os valores e a quantidade de valores registrados. Podemos usar essas s√©ries para pegar a m√©dia aritim√©tica dos valores. A m√©dia pode ser fortemente influenciada por valores extremos, e a an√°lise de percentis √© √∫til para evitar essa influ√™ncia. Mas, se quisermos uma m√©dia aritim√©tica, podemos obet√™-la:</p><pre class="refractor language-js"><code class="language-js"><span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_sum<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">/</span>
<span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_count<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><img src="/media/uma-metrica-grafico-2.png" alt="Gr√°fico de lat√™ncia m√©dia ao longo do tempo, com uma linha"/></p><p>Para fazer essa consulta, al√©m de dividir a soma pelo total (que √© a defini√ß√£o de m√©dia aritim√©tica), estamos usando a fun√ß√£o <code>rate</code>. Ela serve neste caso para que nosso gr√°fico n√£o considere <strong>todas os eventos da hist√≥ria</strong>. Sem o <code>rate</code>, vamos calcular a lat√™ncia m√©dia desde que a aplica√ß√£o iniciou, e n√£o uma m√©dia &quot;instant√¢nea&quot; (que n√£o √© instant√¢nea de fato pois precisamos de uma janela para calcular a m√©dia, neste exemplo, de 5 minutos).</p><p>Com o <code>rate</code>, vamos pegar o quanto a soma dos valores cresceu nos √∫ltimos 5 minutos e dividir por o quanto a quatidade de eventos cresceu nos √∫ltimos 5 minutos. Assim, cada ponto da s√©rie temporal resultante √© a lat√™ncia m√©dia dos √∫ltimos 5 minutos.</p><h2>Disponibilidade (em sucessos/total)</h2><p>Dependendo do conceito de disponibilidade que voc√™ utiliza, a maneira que construimos essa m√©trica serve para fazer uma medi√ß√£o de disponibilidade da sua aplica√ß√£o. Uma das defini√ß√µes, citada no <a href="https://landing.google.com/sre/sre-book/chapters/embracing-risk/">livro de SRE do Google</a>, √© a de <strong>disponibilidade agregada</strong>. Ela parte da ideia de que o uptime (tempo em que o servi√ßo estava dispon√≠vel) pode ser menos relevante do que a quantidade de requisi√ß√µes com sucesso que a aplica√ß√£o atendeu.</p><p>Se uma √°rvore cai numa floresta deserta e ningu√©m escuta, ela faz barulho? Se a sua aplica√ß√£o passa 5 minutos offline mas ningu√©m tentou interagir com ela na quele momento, isso importa? Ficar 5 minutos fora do ar √†s 3 da manh√£ e ao meio-dia para uma aplica√ß√£o de delivery de comida s√£o situa√ß√µes bem diferentes.</p><p>Dado que nossa m√©trica tem uma dimens√£o de <code>status_class</code> e uma s√©rie temporal que representa a quantidade de requisi√ß√µes que aconteceram (a <code>_count</code>), podemos calcular o percentual de disponibilidade instant√¢nea dela dividindo a quantidade de erros pelo total de requisi√ß√µes. Como queremos saber o percentual de requisi√ß√µes que n√£o deu erro, vamos pegar como resultado <code>1 - percentual-de-erros</code>.</p><pre class="refractor language-js"><code class="language-js"><span class="token number">1</span> <span class="token operator">-</span>
<span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_count<span class="token punctuation">{</span>status_class<span class="token operator">=</span><span class="token string">&quot;5XX&quot;</span><span class="token punctuation">}</span><span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">/</span>
<span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_count<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><img src="/media/uma-metrica-grafico-3.png" alt="Gr√°fico de disponibilidade percentual ao longo do tempo. Majoritariamente em 100%, e em alguns momentos a disponibilidade desce at√© 96% e volta a subir"/></p><p>Podemos usar janelas maiores, que mais fazem sentido olhando n√∫meros do que gr√°ficos. Podemos ter um painel no Grafana representando, por exemplo, a disponibilidade nas √∫ltimas 24 horas mudando apenas o tamanho da janela.</p><pre class="refractor language-js"><code class="language-js"><span class="token number">1</span> <span class="token operator">-</span>
<span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_count<span class="token punctuation">{</span>status_class<span class="token operator">=</span><span class="token string">&quot;5XX&quot;</span><span class="token punctuation">}</span><span class="token punctuation">[</span><span class="token number">24</span>h<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">/</span>
<span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_count<span class="token punctuation">[</span><span class="token number">24</span>h<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><img src="/media/uma-metrica-painel.png" alt="Painel de disponibilidade das √∫ltimas 24 horas mostrando o n√∫mero 99,873%"/></p><h2>Top endpoints mais problem√°ticos (percentual)</h2><p>Podemos reutilizar algumas consultas que fizemos acima, com uma agrega√ß√£o por <code>path</code>, para comparar a performance de diferentes endpoints da aplica√ß√£o. Numa aplica√ß√£o muito grande, a lista de endpoints pode ser muito extensa (mesmo tomando cuidado para n√£o inserir interpola√ß√µes nela), e podemos usar a fun√ß√£o <code>topk</code> para diminuir essa lista. Como o nome diz, ela retorna os <code>k</code> maiores valores.</p><p>Vamos usar a mesma consulta do terceiro exemplo, mas adicionando um agrupamento da agrega√ß√£o de soma, <code>by (path)</code>, para termos um percentual de falha para cada endpoint e, com o <code>topk</code>, pegar os 10 maiores percentuais.</p><pre class="refractor language-js"><code class="language-js"><span class="token function">topk</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> 
  <span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_count<span class="token punctuation">{</span>status_class<span class="token operator">=</span><span class="token string">&quot;5XX&quot;</span><span class="token punctuation">}</span><span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token function">by</span> <span class="token punctuation">(</span>path<span class="token punctuation">)</span>
  <span class="token operator">/</span>
  <span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_count<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token function">by</span> <span class="token punctuation">(</span>path<span class="token punctuation">)</span>
<span class="token punctuation">)</span></code></pre><p><img src="/media/uma-metrica-grafico-4.png" alt="Gr√°fico mostrando percentual de erros ao longo do tempo. H√° v√°rias linhas, uma para cada endpoint da aplica√ß√£o que retornou algum erro durante a janela de tempo do gr√°fico. As linhas ficam em 0 na maior parte do tempo, com subidas ocasionais at√© 3%"/></p><p>Neste exemplo, usamos essa fun√ß√£o para montar um gr√°fico. Note que, neste caso, ela pode retornar <strong>mais do que <code>k</code> s√©ries</strong> pois, em algum momento do gr√°fico, uma s√©rie pode deixar de existir pois seu valor n√£o est√° mais entre os <code>k</code> primeiros e, similarmente, novas s√©ries podem surgir. Voc√™ pode tamb√©m formatar essa consulta como uma <strong>tabela</strong> e olhar apenas para o valor mais recente, que certamente vai conter (no m√°ximo) <code>k</code> linhas. No exemplo abaixo, apenas dois endpoints estavam reportando algum erro nos √∫ltimos 5 minutos e, por isso, s√≥ h√° duas linhas na tabela:</p><p><img src="/media/uma-metrica-tabela.png" alt="Tabela mostrando percentual de erros por endpoint da aplica√ß√£o. H√° duas linhas, uma para cada path que teve um erro (primeira coluna), e o valor do percentual de erros (segunda coluna)"/></p><h2>Top endpoints mais lentos (percentil)</h2><p>Seguindo a mesma l√≥gica do exemplo anterior, mas usando a consulta do primeiro exemplo, podemos pegar a lista dos 10 endpoints com os maiores percentis-99 de lat√™ncia. O Grafana tamb√©m permite adicionar valores nas legendas. No gr√°fico abaixo, eu coloquei para mostrar o valor mais recente e ordernar a legenda por esse valor, mostrando os endpoints mais lentos no momento, em ordem, na legenda.</p><pre class="refractor language-js"><code class="language-js"><span class="token function">topk</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> 
  <span class="token function">histogram_quantile</span><span class="token punctuation">(</span><span class="token number">0.99</span><span class="token punctuation">,</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token function">rate</span><span class="token punctuation">(</span>http_request_duration_seconds_bucket<span class="token punctuation">[</span><span class="token number">5</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token function">by</span> <span class="token punctuation">(</span>le<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span></code></pre><p><img src="/media/uma-metrica-grafico-5.png" alt="Gr√°fico de percentil 99 de lat√™ncia ao longo do tempo. H√° v√°rias linhas, uma para cada endpoint da aplica√ß√£o. Um endpoint √© bem mais lento que os outros, com lat√™ncias entre 3 e 15 segundos. Os outros est√£o na casa das centenas ou dezenas de milissegundos"/></p><p>Lembrando que √© importante manter a dimens√£o <code>le</code> na agrega√ß√£o sempre que formos us√°-la dentro de um <code>histogram_quantile</code>.</p><p>Assim como no exemplo anterior, montar um gr√°fico usando <code>topk</code> pode retornar mais de <code>k</code> s√©ries. Al√©m de usar uma tabela, √© poss√≠vel montar um gr√°fico evitando mostrar mais de <code>k</code> s√©ries isso, tomando uma decis√£o de quais s√©ries retornar, em um momento do tempo, e depois consultando apenas essas s√©ries. H√° um exemplo disso <a href="https://www.robustperception.io/graph-top-n-time-series-in-grafana">neste post da Robust Perception</a>.</p><hr/><p>Pra fechar, vale comentar que a gente <strong>n√£o precisa</strong> ter apenas uma m√©trica na aplica√ß√£o. √â perfeitamente aceit√°vel criar uma m√©trica para medir o histograma das lat√™ncias e uma outra para medir o n√∫mero de requisi√ß√µes, com separa√ß√£o por status de retorno e outras dimens√µes. Para esse post, eu me aproveitei de que todo histograma traz consigo um contador de ocorr√™ncias e adicionei as labels que precis√°vamos para montar os gr√°ficos acima.</p><p>Essas consultas podem ser usadas n√£o s√≥ para montar gr√°ficos bonitos no Grafana, mas tamb√©m para criar alertas usando o <a href="https://prometheus.io/docs/alerting/latest/alertmanager/">Alert Manager</a>, componente do Prometheus que roda consultas nele e gera alertas caso essas consultas retornem algum estado em particular. Quais m√©tricas usar para alertar e como definir bons alertas s√£o assuntos interessantes para tratar em posts futuros! :)</p></div><hr/><div class="Poststyles__AfterPost-sc-12qb97v-0 tuaWG"><p class="Poststyles__AfterPostChild-sc-12qb97v-1 gkeqUt">Gostou? <a href="https://twitter.com/intent/tweet?text=%22Montando%205%20gr%C3%A1ficos%20com%20uma%20m%C3%A9trica%20do%20Prometheus%22%20por%20%40Cisneiros%0A%0Ahttps%3A%2F%2Fblog.cisne.dev%2Fmontando-5-graficos-com-uma-metrica-do-prometheus" target="_blank" rel="noopener noreferrer">Que tal compartilhar?</a></p><p class="Poststyles__AfterPostChild-sc-12qb97v-1 Poststyles__Tags-sc-12qb97v-2 fAvgXR">Tags: <span class="Poststyles__Tag-sc-12qb97v-3 kSZCZX"><a href="/tag/prometheus">prometheus</a></span><span class="Poststyles__Tag-sc-12qb97v-3 kSZCZX"><a href="/tag/monitoring">monitoring</a></span><span class="Poststyles__Tag-sc-12qb97v-3 kSZCZX"><a href="/tag/grafana">grafana</a></span></p></div></article></div></div></main><footer class="Footer__Container-b3q04c-0 gdHjSq"><div class="ui__Fit-prwz6b-0 Footer__FooterFit-b3q04c-1 layJcq"><p>¬© <a href="https://cisne.dev">Alexandre Cisneiros</a></p><p><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a></p></div></footer></div><script type="text/javascript">window.__routeInfo = JSON.parse("{\"template\":\"__react_static_root__/src/containers/post\",\"sharedHashesByProp\":{},\"data\":{\"postData\":{\"title\":\"Montando 5 gr\u00E1ficos com uma m\u00E9trica do Prometheus\",\"date\":\"2020-08-20T00:00:00-03:00\",\"slug\":\"montando-5-graficos-com-uma-metrica-do-prometheus\",\"tags\":[\"prometheus\",\"monitoring\",\"grafana\"],\"filePath\":\"2020-08-20-montando-5-graficos-com-uma-metrica-do-prometheus.md\",\"content\":\"A linguagem de consultas do Prometheus, a **PromQL**, permite fazer transforma\u00E7\u00F5es e agrega\u00E7\u00F5es das m\u00E9tricas para extrair dados que n\u00E3o haviam sido reportados diretamente pela aplica\u00E7\u00E3o mas podem ser deduzidos. Nesse post, trago 5 consultas diferentes que podemos fazer para monitorar nossas aplica\u00E7\u00F5es usando apenas _(tecnicamente)_ uma m\u00E9trica! Vamos us\u00E1-las para montar gr\u00E1ficos no Grafana.\\n\\n\u003C!-- summary-break -->\\n\\nEu digo _tecnicamente_ pois vamos usar uma m\u00E9trica do tipo **histograma**, que \u00E9 um [tipo complexo de m\u00E9trica do Prometheus](/tipos-complexos-de-metricas-no-prometheus/). Por baixo, um histograma \u00E9 implementado usando v\u00E1rias s\u00E9ries temporais distintas, mas a biblioteca de cliente do Prometheus abstrai isso e a aplica\u00E7\u00E3o s\u00F3 precisa registrar cada evento em uma \u00FAnica m\u00E9trica.\\n\\nA m\u00E9trica que vamos usar vai registrar a distribui\u00E7\u00E3o da lat\u00EAncia das requisi\u00E7\u00F5es HTTP que a aplica\u00E7\u00E3o recebe, em segundos. Vamos cham\u00E1-la de `http_request_duration_seconds`. Para conseguirmos fazer algumas agrega\u00E7\u00F5es que queremos, vamos adicionar duas dimens\u00F5es a essta m\u00E9trica: `path` que \u00E9 o caminho (ou endpoint) da requisi\u00E7\u00E3o e `status_class` que \u00E9 que tipo retorno foi dado a essa requisi\u00E7\u00E3o, como `2XX`, `4XX`, `5XX`, e por a\u00ED vai.\\n\\nA cria\u00E7\u00E3o e registro dos eventos dessa m\u00E9trica depende da linguagem e framework que voc\u00EA esteja usando. Alguns frameworks possuem integra\u00E7\u00E3o com a biblioteca de cliente do Prometheus para a linguagem e podem j\u00E1 fornecer uma m\u00E9trica como essa. Do contr\u00E1rio, voc\u00EA precisa observar as requisi\u00E7\u00F5es que chegam e reportar uma m\u00E9trica de histograma passando como valor o n\u00FAmero de segundos que ela levou para terminar e, como dimens\u00F5es, pelo menos as duas acima.\\n\\nSobre o `path`, \u00E9 importante lembrar que dimens\u00F5es (labels) no Prometheus n\u00E3o podem ter valores ilimitados, pois isso gera uma carga consider\u00E1vel nele. Uma regra de ouro \u00E9: se voc\u00EA n\u00E3o consegue listar todas as possibilidades de valores pra uma dimens\u00E3o, ela n\u00E3o deveria existir. Para o `path`, isso quer dizer que temos que tomar cuidado com **interpola\u00E7\u00F5es**. Por exemplo, se a aplica\u00E7\u00E3o tem uma rota `/api/users/812376/profile`, em que `812376` representa um ID de usu\u00E1rio, devemos reportar o caminho sem interpola\u00E7\u00F5es, como `/api/users/:id/profile`.\\n\\nSobre o `status_class`, ele \u00E9 uma abstra\u00E7\u00E3o em cima do c\u00F3digo de status da resposta da nossa aplica\u00E7\u00E3o. Por exemplo, se a aplica\u00E7\u00E3o retornar 200 ou 201, o `status_class` seria `2XX`. Se retornar 500 ou 503, seria `5XX`. Isso vai facilitar, por exemplo, filtrarmos todas as requisi\u00E7\u00F5es em que o servidor deu um erro (`5XX`) sem ter que listar todos os poss\u00EDveis c\u00F3digos de erro HTTP.\\n\\nDuas observa\u00E7\u00F5es antes de come\u00E7ar: algumas dessas m\u00E9tricas, medidas do ponto de vista da aplica\u00E7\u00E3o, ser\u00E3o naturalmente enviesadas pois considerar\u00E3o apenas requisi\u00E7\u00F5es que **chegaram a aplica\u00E7\u00E3o e foram respondidas** (mesmo que com um erro 500). Por\u00E9m, se a aplica\u00E7\u00E3o estiver mal das pernas, ela pode come\u00E7ar a derrubar conex\u00F5es, ficar indispon\u00EDvel para reportar m\u00E9tricas, ou ainda um balanceador de carga que sirva a aplica\u00E7\u00E3o comece a enfileirar requisi\u00E7\u00F5es e eventualmente desistr delas. Se voc\u00EA conseguir m\u00E9tricas assim do load balancer, pode ter uma figura mais ver\u00EDdica nos momento de maior aperto.\\n\\nSimilarmente, se voc\u00EA conseguir **coletar m\u00E9tricas no cliente** (navegador, aplicativo, etc), voc\u00EA consegue considerar falhas em requisi\u00E7\u00F5es por raz\u00F5es como problemas de DNS, que nem chegariam no seu load balancer. \u00C9 tamb\u00E9m poss\u00EDvel ver lat\u00EAncia real incluindo o tempo gasto pela conex\u00E3o de rede do usu\u00E1rio, o que \u00E9 interessante de analisar pois, mesmo que voc\u00EA n\u00E3o consiga influenciar muito a velocidade de conex\u00E3o dessa pessoa usando 3G com um pontinho de sinal, entender esse comportamento pode ajudar a otimizar seu conte\u00FAdo para as condi\u00E7\u00F5es mais t\u00EDpicas do seu usu\u00E1rio.\\n\\n## Percentis de lat\u00EAncia\\n\\nCome\u00E7ando por uma das aplica\u00E7\u00F5es mais comuns para histogramas no Prometheus: estimar percentis. Para isso, usamos a fun\u00E7\u00E3o `histogram_quantile` que espera um n\u00FAmero de 0 a 1 (por exemplo, 0.5 \u00E9 o percentil 50, ou mediana).\\n\\nPara esta m\u00E9trica, queremos ver os percentis de lat\u00EAncia para a aplica\u00E7\u00E3o toda, independentemente do endpoint ou c\u00F3digo de retorno. Ent\u00E3o vamos agrupar nossa s\u00E9rie temporal usando `sum`. Sempre que agregamos s\u00E9ries que v\u00E3o ser usadas para a fun\u00E7\u00E3o `histogram_quantile`, precisamos manter a label `le` (mais sobre isso no [post sobre tipos complexos de m\u00E9tricas](/tipos-complexos-de-metricas-no-prometheus/)).\\n\\n```promql\\nhistogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))\\n```\\n```promql\\nhistogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))\\n```\\n```promql\\nhistogram_quantile(0.5, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))\\n```\\n\\n![Gr\u00E1fico de percentis de lat\u00EAncia ao longo do tempo, com tr\u00EAs linhas, cada uma representando um percentil (99, 90 e 50)](/media/uma-metrica-grafico-1.png)\\n\\nCada consulta acima vai retornar uma s\u00E9rie que representa o percentil de lat\u00EAncia (99, 90 e 50, respectivamente). Como para o c\u00E1lculo precisamos usar a fun\u00E7\u00E3o `rate`, precisamos de uma janela para o c\u00E1lculo da m\u00E9trica. Em todos os exemplos deste post vou usar 5 minutos. Esse valor tem que ser, no m\u00EDnimo, maior que o dobro do intervalo entre coletas de m\u00E9trica do Prometheus  (`scrape_interval` na configura\u00E7\u00E3o), pois voc\u00EA precisa de dois pontos de dados para calcular a varia\u00E7\u00E3o.\\n\\n## Lat\u00EAncia m\u00E9dia\\n\\nM\u00E9tricas de histograma incluem, al\u00E9m das s\u00E9ries temporais dos buckets, duas s\u00E9ries a mais que cont\u00E9m a soma de todos os valores e a quantidade de valores registrados. Podemos usar essas s\u00E9ries para pegar a m\u00E9dia aritim\u00E9tica dos valores. A m\u00E9dia pode ser fortemente influenciada por valores extremos, e a an\u00E1lise de percentis \u00E9 \u00FAtil para evitar essa influ\u00EAncia. Mas, se quisermos uma m\u00E9dia aritim\u00E9tica, podemos obet\u00EA-la:\\n\\n```promql\\nsum(rate(http_request_duration_seconds_sum[5m]))\\n/\\nsum(rate(http_request_duration_seconds_count[5m]))\\n```\\n\\n![Gr\u00E1fico de lat\u00EAncia m\u00E9dia ao longo do tempo, com uma linha](/media/uma-metrica-grafico-2.png)\\n\\nPara fazer essa consulta, al\u00E9m de dividir a soma pelo total (que \u00E9 a defini\u00E7\u00E3o de m\u00E9dia aritim\u00E9tica), estamos usando a fun\u00E7\u00E3o `rate`. Ela serve neste caso para que nosso gr\u00E1fico n\u00E3o considere **todas os eventos da hist\u00F3ria**. Sem o `rate`, vamos calcular a lat\u00EAncia m\u00E9dia desde que a aplica\u00E7\u00E3o iniciou, e n\u00E3o uma m\u00E9dia \\\"instant\u00E2nea\\\" (que n\u00E3o \u00E9 instant\u00E2nea de fato pois precisamos de uma janela para calcular a m\u00E9dia, neste exemplo, de 5 minutos).\\n\\nCom o `rate`, vamos pegar o quanto a soma dos valores cresceu nos \u00FAltimos 5 minutos e dividir por o quanto a quatidade de eventos cresceu nos \u00FAltimos 5 minutos. Assim, cada ponto da s\u00E9rie temporal resultante \u00E9 a lat\u00EAncia m\u00E9dia dos \u00FAltimos 5 minutos.\\n\\n## Disponibilidade (em sucessos/total)\\n\\nDependendo do conceito de disponibilidade que voc\u00EA utiliza, a maneira que construimos essa m\u00E9trica serve para fazer uma medi\u00E7\u00E3o de disponibilidade da sua aplica\u00E7\u00E3o. Uma das defini\u00E7\u00F5es, citada no [livro de SRE do Google](https://landing.google.com/sre/sre-book/chapters/embracing-risk/), \u00E9 a de **disponibilidade agregada**. Ela parte da ideia de que o uptime (tempo em que o servi\u00E7o estava dispon\u00EDvel) pode ser menos relevante do que a quantidade de requisi\u00E7\u00F5es com sucesso que a aplica\u00E7\u00E3o atendeu.\\n\\nSe uma \u00E1rvore cai numa floresta deserta e ningu\u00E9m escuta, ela faz barulho? Se a sua aplica\u00E7\u00E3o passa 5 minutos offline mas ningu\u00E9m tentou interagir com ela na quele momento, isso importa? Ficar 5 minutos fora do ar \u00E0s 3 da manh\u00E3 e ao meio-dia para uma aplica\u00E7\u00E3o de delivery de comida s\u00E3o situa\u00E7\u00F5es bem diferentes.\\n\\nDado que nossa m\u00E9trica tem uma dimens\u00E3o de `status_class` e uma s\u00E9rie temporal que representa a quantidade de requisi\u00E7\u00F5es que aconteceram (a `_count`), podemos calcular o percentual de disponibilidade instant\u00E2nea dela dividindo a quantidade de erros pelo total de requisi\u00E7\u00F5es. Como queremos saber o percentual de requisi\u00E7\u00F5es que n\u00E3o deu erro, vamos pegar como resultado `1 - percentual-de-erros`.\\n\\n```promql\\n1 -\\nsum(rate(http_request_duration_seconds_count{status_class=\\\"5XX\\\"}[5m]))\\n/\\nsum(rate(http_request_duration_seconds_count[5m]))\\n```\\n\\n![Gr\u00E1fico de disponibilidade percentual ao longo do tempo. Majoritariamente em 100%, e em alguns momentos a disponibilidade desce at\u00E9 96% e volta a subir](/media/uma-metrica-grafico-3.png)\\n\\nPodemos usar janelas maiores, que mais fazem sentido olhando n\u00FAmeros do que gr\u00E1ficos. Podemos ter um painel no Grafana representando, por exemplo, a disponibilidade nas \u00FAltimas 24 horas mudando apenas o tamanho da janela.\\n\\n```promql\\n1 -\\nsum(rate(http_request_duration_seconds_count{status_class=\\\"5XX\\\"}[24h]))\\n/\\nsum(rate(http_request_duration_seconds_count[24h]))\\n```\\n\\n![Painel de disponibilidade das \u00FAltimas 24 horas mostrando o n\u00FAmero 99,873%](/media/uma-metrica-painel.png)\\n\\n## Top endpoints mais problem\u00E1ticos (percentual)\\n\\nPodemos reutilizar algumas consultas que fizemos acima, com uma agrega\u00E7\u00E3o por `path`, para comparar a performance de diferentes endpoints da aplica\u00E7\u00E3o. Numa aplica\u00E7\u00E3o muito grande, a lista de endpoints pode ser muito extensa (mesmo tomando cuidado para n\u00E3o inserir interpola\u00E7\u00F5es nela), e podemos usar a fun\u00E7\u00E3o `topk` para diminuir essa lista. Como o nome diz, ela retorna os `k` maiores valores.\\n\\nVamos usar a mesma consulta do terceiro exemplo, mas adicionando um agrupamento da agrega\u00E7\u00E3o de soma, `by (path)`, para termos um percentual de falha para cada endpoint e, com o `topk`, pegar os 10 maiores percentuais.\\n\\n```promql\\ntopk(10, \\n  sum(rate(http_request_duration_seconds_count{status_class=\\\"5XX\\\"}[5m])) by (path)\\n  /\\n  sum(rate(http_request_duration_seconds_count[5m])) by (path)\\n)\\n```\\n\\n![Gr\u00E1fico mostrando percentual de erros ao longo do tempo. H\u00E1 v\u00E1rias linhas, uma para cada endpoint da aplica\u00E7\u00E3o que retornou algum erro durante a janela de tempo do gr\u00E1fico. As linhas ficam em 0 na maior parte do tempo, com subidas ocasionais at\u00E9 3%](/media/uma-metrica-grafico-4.png)\\n\\nNeste exemplo, usamos essa fun\u00E7\u00E3o para montar um gr\u00E1fico. Note que, neste caso, ela pode retornar **mais do que `k` s\u00E9ries** pois, em algum momento do gr\u00E1fico, uma s\u00E9rie pode deixar de existir pois seu valor n\u00E3o est\u00E1 mais entre os `k` primeiros e, similarmente, novas s\u00E9ries podem surgir. Voc\u00EA pode tamb\u00E9m formatar essa consulta como uma **tabela** e olhar apenas para o valor mais recente, que certamente vai conter (no m\u00E1ximo) `k` linhas. No exemplo abaixo, apenas dois endpoints estavam reportando algum erro nos \u00FAltimos 5 minutos e, por isso, s\u00F3 h\u00E1 duas linhas na tabela:\\n\\n![Tabela mostrando percentual de erros por endpoint da aplica\u00E7\u00E3o. H\u00E1 duas linhas, uma para cada path que teve um erro (primeira coluna), e o valor do percentual de erros (segunda coluna)](/media/uma-metrica-tabela.png)\\n\\n\\n## Top endpoints mais lentos (percentil)\\n\\nSeguindo a mesma l\u00F3gica do exemplo anterior, mas usando a consulta do primeiro exemplo, podemos pegar a lista dos 10 endpoints com os maiores percentis-99 de lat\u00EAncia. O Grafana tamb\u00E9m permite adicionar valores nas legendas. No gr\u00E1fico abaixo, eu coloquei para mostrar o valor mais recente e ordernar a legenda por esse valor, mostrando os endpoints mais lentos no momento, em ordem, na legenda.\\n\\n```promql\\ntopk(10, \\n  histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, path))\\n)\\n```\\n\\n![Gr\u00E1fico de percentil 99 de lat\u00EAncia ao longo do tempo. H\u00E1 v\u00E1rias linhas, uma para cada endpoint da aplica\u00E7\u00E3o. Um endpoint \u00E9 bem mais lento que os outros, com lat\u00EAncias entre 3 e 15 segundos. Os outros est\u00E3o na casa das centenas ou dezenas de milissegundos](/media/uma-metrica-grafico-5.png)\\n\\nLembrando que \u00E9 importante manter a dimens\u00E3o `le` na agrega\u00E7\u00E3o sempre que formos us\u00E1-la dentro de um `histogram_quantile`.\\n\\nAssim como no exemplo anterior, montar um gr\u00E1fico usando `topk` pode retornar mais de `k` s\u00E9ries. Al\u00E9m de usar uma tabela, \u00E9 poss\u00EDvel montar um gr\u00E1fico evitando mostrar mais de `k` s\u00E9ries isso, tomando uma decis\u00E3o de quais s\u00E9ries retornar, em um momento do tempo, e depois consultando apenas essas s\u00E9ries. H\u00E1 um exemplo disso [neste post da Robust Perception](https://www.robustperception.io/graph-top-n-time-series-in-grafana).\\n\\n---\\n\\nPra fechar, vale comentar que a gente **n\u00E3o precisa** ter apenas uma m\u00E9trica na aplica\u00E7\u00E3o. \u00C9 perfeitamente aceit\u00E1vel criar uma m\u00E9trica para medir o histograma das lat\u00EAncias e uma outra para medir o n\u00FAmero de requisi\u00E7\u00F5es, com separa\u00E7\u00E3o por status de retorno e outras dimens\u00F5es. Para esse post, eu me aproveitei de que todo histograma traz consigo um contador de ocorr\u00EAncias e adicionei as labels que precis\u00E1vamos para montar os gr\u00E1ficos acima.\\n\\nEssas consultas podem ser usadas n\u00E3o s\u00F3 para montar gr\u00E1ficos bonitos no Grafana, mas tamb\u00E9m para criar alertas usando o [Alert Manager](https://prometheus.io/docs/alerting/latest/alertmanager/), componente do Prometheus que roda consultas nele e gera alertas caso essas consultas retornem algum estado em particular. Quais m\u00E9tricas usar para alertar e como definir bons alertas s\u00E3o assuntos interessantes para tratar em posts futuros! :)\\n\",\"readingTime\":10,\"summary\":\"A linguagem de consultas do Prometheus, a **PromQL**, permite fazer transforma\u00E7\u00F5es e agrega\u00E7\u00F5es das m\u00E9tricas para extrair dados que n\u00E3o haviam sido reportados diretamente pela aplica\u00E7\u00E3o mas podem ser deduzidos. Nesse post, trago 5 consultas diferentes que podemos fazer para monitorar nossas aplica\u00E7\u00F5es usando apenas _(tecnicamente)_ uma m\u00E9trica! Vamos us\u00E1-las para montar gr\u00E1ficos no Grafana.\\n\\n\"}},\"path\":\"montando-5-graficos-com-uma-metrica-do-prometheus\",\"sharedData\":{},\"siteData\":{}}");</script><script defer="" type="text/javascript" src="/templates/vendors~__react_static_root__/src/containers/post~__react_static_root__/src/containers/postList.207edc50.js"></script><script defer="" type="text/javascript" src="/templates/__react_static_root__/src/containers/post~__react_static_root__/src/containers/postList.a04ea84b.js"></script><script defer="" type="text/javascript" src="/templates/__react_static_root__/src/containers/post.d8dd52db.js"></script><script defer="" type="text/javascript" src="/templates/vendors~main.272ae1d1.js"></script><script defer="" type="text/javascript" src="/main.f19d4c14.js"></script></body></html>